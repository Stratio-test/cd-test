= Quick start guide

The purpose of this guide is to briefly explain how to integrate an Apache Hive™ database into the _Stratio Generative AI Data Fabric_ platform.

== Prerequisites

You can find the prerequisites for installing the SSCC Apache Hive™ connector in the xref:apache-hive:operations-guide.adoc#_prerequisites[operations guide].

NOTE: Please note that the *Kerberos authentication mode* will be used in this quick start guide.

== Discover your data

=== Discovery agent

To install a _Stratio Data Governance_ discovery agent for Apache Hive™ you must go to '_Stratio Command Center_' -> 'Deploy a Service' -> 'Connectors RDBMS' and select "Hive Agent".

When installing, you have to add the information corresponding to the database instance to be discovered, in addition to the URLs of the connectors repository where the necessary artifacts are stored and upload the access credentials to _Stratio KMS_.

The most important fields to fill in are:

* *_Root discovery path_*: path from which you want to discover the metadata recursively. They must be separated by commas, without spaces, and with a `/` slash at the beginning. Example: `/schema_to_be_discovered,/schema_to_be_discovered2`.
* *_Custom Service URL_*: JDBC URL used to connect to Apache Hive™. Example:  `jdbc:hive2://hiveserver.labs.stratio.com:10000/default;principal=myprincipal/hive.mycompany.com@MYCOMPANY.COM;kerberosAuthType=fromSubject`.
* *_Access credentials_*: name of the secret created in _Stratio KMS_. Example: `hive-secret`.
* *_SSCC driver location_*: URL where the artifact that will contain the JAR of the SSCC Apache Hive™ connector is located in the connectors repository. Example: `http://connectors.<tenant>-<namespace>/v1/api/artifact/sscc-hive-0.3_2.12-1.5.x.jar`.
* *_JDBC driver location_*: URL where the artifact that will contain the JAR of the selected JDBC driver is located in the connectors repository. Example: `http://connectors.<tenant>-<namespace>/v1/api/artifact/hive-jdbc-2.2.0-1.0.x.jar`.

TIP: More information on the other configuration parameters can be found in the xref:apache-hive:operations-guide.adoc[operations guide].

Once the discovery process is completed, the data store will appear in the _Stratio Data Governance_ UI.

== Virtualize your data

=== Eureka agent

To use the BDL, you need to configure the Eureka agent with the Apache Hive™ connector. To do this, simply add the URL of the connectors repository of the artifact in the 'Customized deployment' -> 'Settings' -> `Additional jars` variable.

In the example being followed, the Eureka agent looks like this:

* _Additional jars_: `http://connectors.<tenant>-<namespace>/v1/api/artifact/sscc-hive-0.3_2.12-1.5.x.jar`.

=== _Stratio Virtualizer_

To use _Stratio Virtualizer_ you need to have the Apache Hive™ connector configured. To do so, you need to add the URL of the artifact in the 'Customized deployment' -> 'Environment' -> 'External datastores' -> `JDBC Drivers URL List` variable and also upload the access credentials to _Stratio KMS_.

* _JDBC Drivers URL List_: `http://connectors.<tenant>-<namespace>/v1/api/artifact/hive-jdbc-2.2.0-1.0.x.jar,http://connectors.<tenant>-<namespace>/v1/api/artifact/sscc-hive-0.3_2.12-1.5.x.jar`.

== Transform your data

=== _Stratio Rocket_

To use _Stratio Rocket_ you need to have the Apache Hive™ connector configured. To do this, you must add the URL of the artifact in the 'Customized deployment' -> 'Settings' -> 'Classpath' -> `Rocket extra jars` variable and xref:apache-hive:operations-guide.adoc[upload the access credentials for workflows and for _Stratio Rocket_ to _Stratio KMS_].

In the example being followed, _Stratio Rocket_ would look like this:

* *_Rocket extra jars_*: `http://connectors.<tenant>-<namespace>/v1/api/artifact/hive-jdbc-2.2.0-1.0.x.jar,http://connectors.<tenant>-<namespace>/v1/api/artifact/sscc-hive-0.3_2.12-1.5.x.jar`.

After applying these changes, you should be able to access the Apache Hive™ virtualized collection via SQL queries directly in the catalog or via a _Stratio Virtualizer_ input in a workflow.

=== _Stratio Intelligence_

You'll need to configure _Stratio Intelligence_ before integrating with the connector, which is described in xref:ROOT:quick-start-guide#_stratio_intelligence [the general quick start guide].

Once you've configured _Stratio Intelligence_, you have to add the Apache Hive™ connector to the _artifacts/spark++_++jars_ directory and upload the credentials to _Stratio KMS_.

To upload the artifacts, you have to download them from the _artifacts/spark++_++jars_ directory into the _Stratio Intelligence_ workspace by issuing a cURL request.
In this case, you could make the following request:

[source,bash]
----
curl http://connectors.<tenant>-<namespace>/v1/api/artifact/sscc-hive-0.3_2.12-1.5.x.jar --output sscc-hive-0.3_2.12-1.5.x.jar
curl http://connectors.<tenant>-<namespace>/v1/api/artifact/hive-jdbc-2.2.0-1.0.x.jar --output hive-jdbc-2.2.0-1.0.x.jar
----

Once this is configured, you will be able to access the tables that have been virtualized from the external Apache Hive™ database.
