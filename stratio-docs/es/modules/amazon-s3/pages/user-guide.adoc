= Guía de usuario

El propósito de esta guía es explicar el funcionamiento particular del conector SSCC Amazon S3 para un usuario en la plataforma _Stratio Generative AI Data Fabric_.

== Descripción

Amazon S3 es un almacenamiento externo incluido en Amazon Web Services (AWS) que se puede emplear para almacenar cualquier tipo de objeto que permita usos como el almacenamiento para aplicaciones de internet, _backup_ y _restore_, recuperación ante desastres, archivos de datos, _data lakes_ para análisis y almacenamiento híbrido en la nube.

_Stratio Generative AI Data Fabric_ puede realizar tareas de descubrimiento de los metadatos de Amazon S3. La jerarquía soportada por el conector es:

. Cuenta de Amazon S3.
. _Bucket_.
. Uno o varios directorios.
. Fichero.

TIP: Consulta la https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html[guía oficial de Amazon S3] para más información.

Para que el conector pueda acceder a tus datos deberás tener un usuario creado, como se muestra en los xref:amazon-s3:operations-guide.adoc#_prerrequisitos[prerrequisitos] de la guía de operaciones, con el que quieras que _Stratio Generative AI Data Fabric_ realice el descubrimiento. Si la cuenta no tiene los permisos suficientes, el proceso de descubrimiento fallará.

Estas son las vistas en el descubrimiento:

*DataSource*

image::vista_general_datasource_s3.png[]

Atributos:

- _proxyEnabled_ (sólo aparece si el proxy está habilitado): indica que se ha activado la conexión a través del proxy.
- _proxyAuthEnabled_ (sólo aparece si el proxy está habilitado): indica que se ha activado la autenticación de la conexión a través del proxy.
- _proxyHost_ (sólo aparece si el proxy está habilitado): _host_ del proxy utilizado para la conexión.
- _proxyPort_ (sólo aparece si el proxy está habilitado): puerto del proxy utilizado para la conexión.
- _proxyProtocol_ (sólo aparece si el proxy está habilitado): protocolo del proxy utilizado para la conexión: HTTP o HTTPS.

*Cuentas*

image::vista_general_cuentas_s3.png[]

Atributos:

- _type_: tipo de almacén de datos Amazon S3.
- _displayName_: nombre de la cuenta de Amazon S3.
- _id_: ID de la cuenta de Amazon S3.

*_Buckets_*

image::vista_general_buckets_s3.png[]

Atributos:

- _type_: tipo de almacén de datos Amazon S3.
- _CreationDate_: fecha de creación del _bucket_.
- _Name_: nombre del _bucket_.
- _Owner_: usuario propietario del _bucket_.

*Directorios*

image::vista_general_dir_s3.png[]

Atributos:

- _type_: tipo de almacén de datos Amazon S3.
- _accountName_: nombre de la cuenta a la que pertenece.
- _bucketName_: nombre del _bucket_ al que pertenece.
- _key_: nombre del directorio.

*Tabla*

image::vista_general_tabla_s3.png[]

Atributos:

- _accountName_: nombre de la cuenta a la que pertenece.
- _bucketName_: nombre del _bucket_ al que pertenece.
- _eTag_: _tag_ interno de Amazon S3.
- _format_: formato del fichero.
- _key_: ruta relativa del fichero.
- _lastModified_: fecha de última modificación.
- _size_: tamaño del fichero en _bytes_.
- _storageClass_: clase de almacenamiento utilizada en Amazon S3.

*Columnas*

image::vista_columna_s3.png[]

Atributos:

- _type_: tipo de almacén de datos Amazon S3.
- _sourceType_: tipo original de la columna en el almacén de datos.

El agente _cloud_ funciona de la siguiente manera:

* Es capaz de identificar sistemas de ficheros jerárquicos a partir de la raíz identificada a primer nivel en un _bucket_ Amazon S3.
* Si dentro de cualquier directorio encuentra xref:amazon-s3:compatibility-matrix.adoc#_formatos_soportados[un fichero soportado], es capaz de obtener los metadatos y representarlo como si fuese una tabla de tipo SQL.

== Virtualiza tus datos

Una vez descubiertas las tablas, puedes añadirlas a la vista técnica de una colección. Todos los parámetros configurables del descubrimiento y los modificados desde la interfaz de usuario de _Stratio Data Governance_ se propagan en las colecciones donde se añada esa tabla.

TIP: Puedes leer más acerca de sus características en la xref:stratio-virtualizer:user-guide:user-guide.adoc#_trabajar_con_stratio_virtualizer[guía de usuario de _Stratio Virtualizer_].

NOTE: Ten en cuenta que para virtualizar las tablas descubiertas es necesario gestionar las xref:stratio-gosec:operations-manual:data-access/manage-policies/manage-domains-policies.adoc[políticas de dominios] a través de _Stratio GoSec_.

Para crear una tabla directamente en el catálogo de _Stratio Virtualizer_ puedes ejecutar una de las siguientes sentencias:

* Usando una credencial global tal y como se describe en xref:amazon-s3:operations-guide.adoc#direct-access-to-resources[la guía de operaciones].
+
[source,sql]
----
CREATE TABLE `s3_table` USING parquet LOCATION 's3a://my-bucket/path/to/my/file.parquet'
----

* Usando una credencial específica para la tabla.
** Con autenticación _Service Account_.
+
[source,sql]
----
CREATE TABLE `s3_table`
USING parquet
OPTIONS (
  `stratiocredentials` 's3-sa-secret',
  `stratiosecurity` 'true',
  `stratiossccdriver` 'com.stratio.connectors.ssccs3.S3DriverServiceAccount',
  `stratiosecuritymode` 'custom_sscc',
  `fs.s3a.aws.credentials.provider` 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider'
) LOCATION 's3a://my-bucket/path/to/my/file.parquet'
----

** Con autenticación _Assume Role_.
+
[source,sql]
----
CREATE TABLE `s3_table`
USING parquet
OPTIONS (
  `stratiocredentials` 's3-ar-secret',
  `stratiosecurity` 'true',
  `stratiossccdriver` 'com.stratio.connectors.ssccs3.S3DriverAssumeRole',
  `stratiosecuritymode` 'custom_sscc',
  `fs.s3a.aws.credentials.provider` 'org.apache.hadoop.fs.s3a.auth.AssumedRoleCredentialProvider'
) LOCATION 's3a://my-bucket/path/to/my/file.parquet'
----

== Transforma tus datos

=== _Stratio Rocket_

En _Stratio Rocket_ puedes utilizar cualquier _workflow_ para realizar tus operaciones con los datos de Amazon S3. Utiliza cajas de _Stratio Crossdata_ o de tipo SQL como entrada de tus _workflows_:

image::rocket_workflow_1.png[Rocket Workflow Crossdata Box]

image::rocket_workflow_2.png[Rocket Workflow]

También puedes acceder directamente mediante el catálogo:

image::rocket_catalog.png[Rocket Catalog]

La escritura en Amazon S3 está soportada. Utiliza una caja de _Stratio Virtualizer_ para realizar escrituras directamente sobre otro fichero. En este caso, debes realizar escrituras sobre un fichero concreto.

El conector puede trabajar con reglas de calidad para realizar comprobaciones sobre los datos de Amazon S3.

Cuando un _workflow_ de _Stratio Rocket_ se haya ejecutado, puedes visualizar su linaje técnico accediendo sobre la tabla en la colección técnica, como se muestra en la imagen:

image::linage_aws.png[Linaje,500]

=== _Stratio Intelligence_

Puedes utilizar una sesión de _Stratio Virtualizer_ en _Stratio Intelligence_ para acceder rápidamente a tus datos mediante un Jupyter Notebook (utiliza una sesión de PySpark). A continuación se muestra un ejemplo para que puedas hacerlo:

image::intelligence_virtualized_table_1.png[Intelligence virtualized table 1]

image::intelligence_virtualized_table_2.png[Intelligence virtualized table 2]

TIP: Para más información acerca de la consistencia de datos desde _Stratio Intelligence_ ve al documento de xref:ROOT:commiters.adoc[integración].
