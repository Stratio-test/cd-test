= Azure Data Lake Gen2

Es un almacenamiento externo incluido en Azure Cloud Platform. Está basado en HDFS con un conjunto de funcionalidades adicionales, como el _namespace_ jerárquico, que permite la creación de perfiles a nivel de directorio y de fichero.

== Matriz de soporte

|===
| Módulo | Versiones | Azure Data Lake Gen2

| _Stratio Spark_
| ≥ 2.4.4-3.1.0
| OK

| _Stratio Virtualizer_
| ≥ 2.21.0
| OK

| _Stratio Data Governance_
| ≥ 1.5.0
| OK

| _Stratio Rocket_
| ≥ 1.1.0
| OK

| _Stratio Sparta_
| ≥ 2.15
| OK

| _Stratio Intelligence_
| -
| -

| _Stratio BDL_
| ≥ 1.6.0
| OK
|===

:note-caption: AVISO

NOTE: Los módulos sin versiones no han sido probados aún. Podrían estar soportados.

== _Stratio Spark_

=== Acceso al dato

_Stratio Spark_ incluye las dependencias del cliente de Hadoop para soportar Azure Data Lake Gen2.

Admite formatos de archivo Parquet, CSV, JSON y ORC. Los formatos XML y Avro son compatibles con Spark, pero es necesario añadir algunas dependencias que no están incluidas en _Stratio Spark_. También se ha probado a crear particiones con archivos Parquet.

Desde _Stratio Spark_ 2.4.4-3.3.0, se admite la conexión segura a varias cuentas de Azure Data Lake Gen2 al mismo tiempo.

=== Autorización/gestión de secretos

Azure Data Lake Gen2 soporta 2 métodos de autorización: con *credenciales del cliente (OAuth 2.0)* y con *clave compartida*. Para ambos, el equipo de Spark ha realizado un desarrollo en _Stratio Spark_ para almacenar los secretos en Vault.

==== Credenciales del cliente (OAuth 2.0)

Esta es *la forma recomendada*. Para usar este método, necesitas almacenar los secretos en Vault. Pide al administrador del sistema que lo haga por ti.

:important-caption: IMPORTANTE

IMPORTANT: Es importante que incluyas el nombre de la cuenta de Azure al final de la ruta de Vault, será utilizado para establecer propiedades internas.

* *Ruta de Vault*: `/v1/userland/passwords/<stratio_tenant>-<account_name>`.
* *Ejecutar en vCLI*: `put <stratio_tenant>-<account_name> {"user": "<client_id>", "pass": "<client_secret>"}`.

:note-caption: AVISO

NOTE: Si estás usando _Stratio Spark_ en DC/OS sin soporte _multi-tenant_, no puedes configurar el nombre de la cuenta en la ruta de Vault. En su lugar, debes establecer esta propiedad de Spark: _"spark.mesos.dirverEnv.SPARK_SECURITY_ADLS2_ACCOUNT_NAME": "<account_name>"_

Después, puedes lanzar el _job_ de Spark con las siguientes propiedades:

[source]
----
"spark.mesos.driverEnv.SPARK_SECURITY_ADLS2_ENABLE": "true",
"spark.mesos.dirverEnv.SPARK_SECURITY_ADLS2_VAULT_PATH": "/v1/userland/passwords/<stratio_tenant>-<account_name>",
"spark.hadoop.fs.azure.account.oauth2.client.endpoint.<account_name>.dfs.core.windows.net": "https://login.microsoftonline.com/<directory_id>/oauth2/token",
"spark.hadoop.fs.azure.skipUserGroupMetadataDuringInitialization": "true"
----

Desde la versión 3.3.0 de _Stratio Spark_, hay algunos cambios en las variables de entorno para soportar múltiples cuentas:

[source]
----
"spark.mesos.driverEnv.SPARK_SECURITY_ADLS2_ENABLE": "true",
"spark.mesos.dirverEnv.SPARK_SECURITY_ADLS2_<account_name>_VAULT_PATH": "/v1/userland/passwords/<stratio_tenant>-azure",
"spark.hadoop.fs.azure.account.oauth2.client.endpoint.<account_name>.dfs.core.windows.net": "https://login.microsoftonline.com/<directory_id>/oauth2/token",
"spark.hadoop.fs.azure.skipUserGroupMetadataDuringInitialization": "true"
----

* ``account_name``: cuenta de almacenamiento en Azure. Por ejemplo: _stratiospk_,
* ``directory_id``: identificador del _tenant/directory_ en Azure. Puedes encontrarlo en: _Azure active directory → Tenant ID_. Por ejemplo: _9c2f8eb6-5bf1-4597-8f4b-0357395935f5_.

Se requiere la propiedad ``“spark.hadoop.fs.azure.skipUserGroupMetadataDuringInitialization”`` para acceder a Azure y Kerberized HDFS en el mismo _job_.

==== Clave compartida

No se recomienda el uso de este método por motivos de seguridad, ya que no existe un control de acceso más allá de estar en posesión de la clave compartida. Desde _Stratio Spark_ 2.4.4-3.3.0, es posible almacenar la clave compartida en Vault.

Para usar la autorización de clave compartida del cliente, debes almacenar los secretos en Vault. Pídele al administrador del sistema que lo haga por ti.

Estas son las propiedades para lanzar el _job_ de Spark:

[source,json]
----
"spark.mesos.driverEnv.SPARK_SECURITY_ADLS2_ENABLE": "true",
"spark.mesos.dirverEnv.SPARK_SECURITY_ADLS2_<account_name>_ACCESSKEY_VAULT_PATH": "/v1/userland/passwords/<stratio_tenant>-azure",
"spark.hadoop.fs.azure.skipUserGroupMetadataDuringInitialization": "true"
----

* account_name: cuenta de almacenamiento en Azure. Por ejemplo: _stratiospk_.

Se requiere la propiedad ``“spark.hadoop.fs.azure.skipUserGroupMetadataDuringInitialization”`` para acceder a Azure y Kerberized HDFS en el mismo _job_.

=== Guía de usuario

El primer paso es elegir uno de los métodos de autorización, configurar las credenciales en Azure y almacenar los secretos en Vault. Luego, debes configurar las propiedades de Spark para descargar los secretos y establecer los accesos al almacén de datos. Una vez configurado el almacén de datos, se accederá a él como si fuera un sistema de archivos normal (como HDFS). Consulta la <<_autorizacióngestión_de_secretos, la sección de Administración de autorización/secretos>> para obtener instrucciones.

La URI utilizada por Azure Data Lake Gen2 para localizar los diferentes recursos es la siguiente:

[source,text]
----
abfss://<file_system>@<account_name>.dfs.core.windows.net/<path_to_file>
----

Un ejemplo de código de Spark:

[source,scala]
----
val df = spark.read.
 parquet("abfss://filesystem01@stratiospk.dfs.core.windows.net/userdata1.parquet")

df.show()
----

Lanza el _job_ de Spark utilizando _Spark Dispatcher_. Debes establecer estas propiedades en el _job_ para descargar los secretos. La ruta de Vault será proporcionada por el administrador del sistema.

== _Stratio Virtualizer_

=== Acceso al dato

El acceso a los datos se realiza a través de _Stratio Spark_. Mira en <<_stratio_spark, la sección de _Stratio Spark_>> para más información.

=== Autorización/gestión de secretos

_Stratio Virtualizer_ utiliza los mismos métodos de autorización soportados en _Stratio Spark_.

El método recomendado es con *credenciales del cliente (OAuth 2.0)* y los secretos se pueden almacenar de manera segura en Vault. También es posible configurar las credenciales en texto sin formato utilizando variables de entorno, pero este método no se recomienda por razones de seguridad.

=== Guía de usuario

Para realizar una prueba, es necesario tener una cuenta de Azure, crear una cuenta de almacenamiento (tipo Data Lake Gen2) y después un sistema de ficheros BLOB (en contenedores).

Antes de nada, necesitas guardar las credenciales en Vault. Tienes que pedirle al administrador del sistema que lo haga por ti. Consulta <<_stratio_spark, la sección de secretos de _Stratio Spark_>> para obtener instrucciones.

El siguiente paso es desplegar _Stratio Virtualizer_ utilizando _Stratio Command Center_. Puedes encontrarlo en *_Environment_ → _External data stores_ → Azure Data Lake Gen2 _integration_*.

:important-caption: AVISO

NOTE: El descriptor de _Stratio Command Center_ está disponible desde la versión 2.22.0. Para versiones anteriores, tienes que hablar con el administrador del sistema.

Una vez desplegado, es posible registrar la tabla en el catálogo y ejecutar consultas.

[source,text]
----
-- Read an existing parquet file
CREATE TABLE azure_1 USING parquet OPTIONS (path 'abfss://filesystem01@stratiospk.dfs.core.windows.net/userdata1.parquet');
SELECT * from azure_1;

-- Create a new parquet file in Azure with two columns and five rows.
CREATE TABLE azure_2 USING parquet OPTIONS (path 'abfss://filesystem01@stratiospk.dfs.core.windows.net/myfile.parquet') AS SELECT 1 AS id, 'Roque' AS name UNION SELECT 2 AS id, 'Miguel Angel' AS name UNION SELECT 3 AS id, 'Ivan' AS name UNION SELECT 4 AS id, 'Alberto' AS name UNION SELECT 5 AS id, 'Juan Miguel' AS name;
SELECT * from azure_2;
----

== _Stratio Data Governance_

=== Acceso al dato

El agente de descubrimiento de HDFS tiene soporte para descubrimiento de metadatos de Azure utilizando el cliente de Hadoop Azure. Los formatos de archivo admitidos son Parquet y Avro.

=== Autorización/gestión de secretos

El agente de descubrimiento actualmente soporta los métodos de autorización con *credenciales del cliente (OAuth 2.0)* y con *clave compartida*. Los secretos pueden almacenarse de forma segura en Vault. Consulta la sección de <<_stratio_spark,_Stratio Spark_>> para obtener más información.

:tip-caption: CONSEJO

TIP: Es muy recomendable crear un usuario dedicado para el agente de descubrimiento con permisos limitados.

=== Guía de usuario

Requisitos previos:

*  Una cuenta de almacenamiento de Azure (tipo Data Lake Gen2) con acceso al sistema de ficheros de BLOB.
* Una instalación de _Stratio Data Governance_.

El primer paso es crear los secretos en Vault. El instalador de _Stratio Command Center_ no los crea automáticamente, por lo que debes pedirle al administrador del sistema que lo haga por ti.

:tip-caption: CONSEJO

TIP: Se recomienda crear un nuevo usuario en Azure para _Stratio Data Governance_ con permisos limitados.

Utiliza el descriptor de _Stratio Command Center_ para instalar el agente de descubrimiento de HDFS para Azure: _agent-cloud-default_.

Los campos más importantes a rellenar en la instalación son:

*General*

* _Backend_ de _Stratio Data Governance_ (PostgreSQL)
 ** _Host_: instancia de PostgreSQL para guardar metadatos de Azure Data Lake Gen2.
* Configuración externa:
 ** HDFS a descubrir.
  *** _Data store type_: ADLS2.
  *** _Default FS_: sistema de archivos predeterminado. Por ejemplo: abfss://filesystem01@stratiospk.dfs.core.windows.net.
  *** _Init path_: ruta desde la que deseas descubrir los metadatos de forma recursiva. Establece "/" si no estás seguro.
 ** Configuración de Azure Data Lake Gen2.
  *** _Authorization method_: puede ser OAUTH (credenciales del cliente) o ACCESS KEY. En ambos casos, los secretos deben almacenarse en Vault.
  *** _OAuth2 Tenant/Directory ID_: solo para la autenticación OAuth. Por ejemplo: 9c2f8eb6-5bf1-4597-8f4b-0357395935f5.
 ** Identidad de servicio.
  *** _Vault role_: se recomienda crear un nuevo rol para los agentes de descubrimiento. Por ejemplo: s000001-dg-agent.
 ** Red de Calico.
  *** _Network name_: es necesario utilizar la red compartida de Stratio si el agente de descubrimiento está configurado para guardar los metadatos en Postgreseos.

*Configuración*

* Ruta de secretos:
 ** _Vault path_: ruta de Vault con las credenciales de autorización. Por ejemplo: s000001-dg-azure-agent.
** _Instance name_: secreto de Vault con las credenciales de autorización. Por ejemplo: s000001-dg-azure-agent.

Comprueba que el servicio despliega, es capaz de descargar el _driver_ y los secretos y comienza el proceso de descubrimiento. La primera vez puede tardar un tiempo.

Si el servicio funciona correctamente, puedes ver los metadatos descubiertos en las trazas:

[source,text]
----
Extract begins at: Fri Mar 27 09:56:05 CET 2020
NewOrUpdate 14 DataAssets begins at: Fri Mar 27 09:56:06 CET 2020
Delete 0 DataAssets begins at: Fri Mar 27 09:56:07 CET 2020
Synchronizing 14 and 0 Federated DataAssets begins at: Fri Mar 27 09:56:07 CET 2020
----

En la interfaz de usuario de _Stratio Data Governance_, puedes ver que se ha descubierto un nuevo almacén de datos y puedes examinar los metadatos. Todos los archivos, columnas y tipos de datos se han detectado correctamente.

image::external-azuregen2-connector-governance.png[]

El agente actualiza los metadatos periódicamente. Se puede realizar una prueba, por ejemplo, al cargar un nuevo archivo en Azure y esperando a que el agente detecte el cambio. Estos cambios se reflejan en la interfaz de usuario de _Stratio Data Governance_.

== _Stratio Rocket_/_Stratio Sparta_

El acceso a los datos se realiza a través de _Stratio Spark_. Consulta la sección <<_stratio_spark,_Stratio Spark_>> para obtener más información.

El descriptor de _Stratio Command Center_ incluye soporte para este almacén de datos utilizando el método de autenticación con credenciales del cliente (OAuth 2.0). Puedes encontrar los campos de Azure Data Lake Gen2 en la sección *_General_ → _External configuration_ → _Adl2 configuration enabled_*.

Los campos más importantes para completar la instalación son:

*General*

* Configuración externa:
 ** _Configuration enabled_: habilita el soporte de Azure Data Lake Gen2.
 ** _Credentials Vault path_: ruta de Vault con los secretos. Esto lo proporciona el administrador del sistema.
  *** _Storage account in Azure_: nombre de la cuenta de almacenamiento. Por ejemplo: stratiospk.
  *** _Tenant/directory identifier in Azure_: ID del directorio. Por ejemplo: 9c2f8eb6-5bf1-4597-8f4b-0357395935f5.

Existe documentación específica para este conector en la página de despliegue de xref:stratio-rocket:operations-guide:installing-and-upgrading/deployment/keos-environment-variables.adoc[_Stratio Rocket_], donde puedes obtener más información sobre cómo configurar estos pasos.

:note-caption: AVISO

NOTE: _Stratio Spark_ 2.4.4-3.1.0 lee el nombre de la cuenta de almacenamiento de la ruta de Vault, así que asegúrate de que la ruta termine con el siguiente formato: _"v1/userland/passwords/ ... /<stratio_tenant>-<account_name>"_. Esta limitación se ha arreglado en versiones posteriores de _Stratio Spark_.

== _Stratio GoSec_

Los almacenes de datos externos no están integrados en _Stratio GoSec_.

La autorización se configurará directamente en la base de datos cuando se cree el usuario para _Stratio Virtualizer_/_Stratio Spark_/_Stratio Data Governance_.

:tip-caption: CONSEJO

TIP: Es muy recomendable crear un usuario específico para cada aplicación con permisos limitados.

La mayoría de los módulos accederán al almacén de datos a través de _Stratio Virtualizer_. Esto te permite configurar diferentes políticas de autorización para cada usuario en _Stratio GoSec_.

Los secretos (usuario/contraseña) se pueden almacenar en Vault de forma segura. _Stratio Virtualizer_/_Stratio Spark_/_Stratio Data Governance_ tienen mecanismos para descargar los secretos y usarlos cuando sea necesario.

== Problemas conocidos

* Admite los formatos de archivo Parquet, CSV, JSON y ORC. Los formatos XML y Avro son compatibles con Spark, pero es necesario añadir algunas dependencias que no están incluidas en _Stratio Spark_. También se ha probado a crear particiones con archivos Parquet.
* El descriptor de _Stratio Command Center_ incluye soporte para este almacén de datos desde la versión 2.22.0. Para versiones anteriores, debes desplegar un _Stratio Virtualizer_ y después cambiar algunas variables de entorno.
* El descriptor de _Stratio Command Center_ incluye soporte para este almacén de datos mediante el método de autenticación OAuth2. Tienes que desplegar una instancia normal de _Stratio Rocket_ o _Stratio Sparta_ rellenando la sección dedicada a este conector localizada debajo de la sección ADLS2 en la vista principal.
