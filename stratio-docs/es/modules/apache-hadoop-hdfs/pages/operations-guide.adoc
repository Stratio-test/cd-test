= Guía de operaciones

== Descripción

El conector Apache Hadoop® (HDFS) te permite la integración de Apache Hadoop® (HDFS) en _Stratio Generative AI Data Fabric_.

Las funcionalidades y versiones soportadas se encuentran en la xref:apache-hadoop-hdfs:compatibility-matrix.adoc[matriz de compatibilidad].

=== Autenticación

Para conectar a un Apache Hadoop® (HDFS) externo se usa el método de autenticación https://kerberos.org/[*Kerberos*].

== Prerrequisitos

* En el caso de que quieras usar un Apache Hadoop® (HDFS) instalado dentro de la plataforma _Stratio Generative AI Data Fabric_, necesitas:
+
. Tener el _framework_ de Apache Hadoop® (HDFS) instalado.

* En el caso de que quieras usar un Apache Hadoop® (HDFS) externo a la plataforma, necesitas:
+
. Un _ConfigMap_ que contenga el _hdfs-site.xml_ y el _core-site.xml_.
. Un _ConfigMap_ que contenga el _krb5.conf_ configurado.
. Tener accesible la interfaz de usuario de _Stratio KMS_ para la gestión de credenciales:
+
Visita la sección de la xref:ROOT:quick-start-guide.adoc[interfaz de usuario de _Stratio KMS_] para consultar los pasos necesarios para tenerla disponible.
+
. Crear los secretos en _Stratio KMS_. Para ello debes acceder a `https://<stratio_kms_ui_url>/ui/vault/secrets` y crear un secreto en la carpeta correspondiente del servicio con las siguientes opciones:
+
--
** _<ServiceId>.<Tenant>-<Namespace>_keytab_: _keytab_ codificado en Base64.
** _<ServiceId>.<Tenant>-<Namespace>_principal_: _principal_ con el que se va hacer _login_ en el Apache Hadoop® (HDFS) asociado al _keytab_.
+
Para realizar la codificación a Base64 del _keytab_ puedes utilizar el siguiente comando:
+
[source,bash]
----
cat /tmp/hdfsExternal.keytab | base64 -w 0 > base64KeytabHdfsExternal
----
+
IMPORTANT: Ten en cuenta que este secreto hay que subirlo en la ruta `/userland/kerberos/` con el nombre `<ServiceId>.<Tenant>-<Namespace>`.

* En el caso de que quieras conectarte a varios HDFS (multi-HDFS), necesitas:
+
--
. Tener desplegados dos HDFS.
. Desplegar un agente de HDFS por cada HDFS.
+
NOTE: Para el HDFS extra, en el despliegue del agente se debe habilitar el campo _Enable Stratio Multi-HDFS_ y especificar el nombre del HDFS. Ejemplo: _hdfs2.stratio-datastores_.
--

== Descubre tus datos

=== Agente de descubrimiento (Apache Hadoop® (HDFS) interno)

Para instalar un agente de descubrimiento de _Stratio Data Governance_ para Apache Hadoop® (HDFS) debes seleccionar en '_Stratio Command Center_' -> 'Deploy a Service' -> 'Governance' el agente "Apache Hadoop® (HDFS) Agent (Internal)".

En la sección 'Pre-deployment':

* *_HDFS used for connection_*: Apache Hadoop® (HDFS) que será descubierto. Ejemplo: _hdfs.s000001-datastores_.
+
image::hdfs-cct-deployment2.png[]

Los campos a rellenar para la instalación son:

* *General*:
** *_Service ID_*: identificador único del agente. Ejemplo: _dg-hdfs-agent_.
** *_Name of the Service_*: nombre mostrado. Ejemplo: _dg-hdfs-agent_.
** *_Execute prerequisites_*: _check_ para crear las políticas de acceso al Apache Hadoop® (HDFS) interno de _Stratio Generative AI Data Fabric_.
* *Metadata Data store (PostgreSQL®)*
** *_Host_*: instancia de PostgreSQL® que almacena los metadatos de Apache Hadoop® (HDFS). Ejemplo: _pgbouncer-postgreskeos-governance.keos-core_.
* *Configuration of the service to be discovered*
** *HDFS to be discovered*
*** *_HDFS ConfigMap_*: nombre del _ConfigMap_ que contiene el _hdfs-site.xml_ y el _core-site.xml_.
*** *_Kerberos ConfigMap_*: nombre del _ConfigMap_ que contiene la configuración de Kerberos asociada al Apache Hadoop® (HDFS). Ejemplo: _keos-kerberos-config_.
*** *_Init path_*: ruta desde la que se quieren descubrir los metadatos de forma recursiva. Ejemplo: _/path_.
+
image::hdfs-cct-deployment1.png[]
+
image::hdfs-cct-deployment3.png[]

El proceso de descubrimiento es asíncrono, una vez terminado el descubrimiento se podrá visualizar desde la interfaz de usuario de _Stratio Data Governance_.

image::hdfs-discover-metadata.png[]

=== Agente de descubrimiento (Apache Hadoop® (HDFS) externo)

Para instalar un agente de descubrimiento de _Stratio Data Governance_ para Apache Hadoop® (HDFS) debes seleccionar en '_Stratio Command Center_' -> 'Deploy a Service' -> 'Governance' el agente "Apache Hadoop® (HDFS) Agent (External)".

Los campos a rellenar para la instalación son:

* *General*:
** *_Service ID_*: identificador único del agente. Ejemplo: _dg-hdfs-agent-external_.
** *_Name of the Service_*: nombre mostrado. Ejemplo: _dg-hdfs-agent-external_.
* *Metadata Data store (PostgreSQL®)*
** *_Host_*: instancia de PostgreSQL® que almacena los metadatos de Apache Hadoop® (HDFS). Ejemplo: _pgbouncer-postgreskeos-governance.keos-core_.
* *Configuration of the service to be discovered*
** **HDFS to be discovered*
*** *_HDFS ConfigMap_*: nombre del _ConfigMap_ que contiene el _hdfs-site.xml_ y el _core-site.xml_. Ejemplo: _hdfs-external-config_.
*** *_Kerberos ConfigMap_*: nombre del _ConfigMap_ que contiene la configuración de Kerberos asociada al Apache Hadoop® (HDFS). Ejemplo: _kerberos-external-config_.
*** *_Init path_*: ruta desde la que se quieren descubrir los metadatos de forma recursiva. Ejemplo: _/path_.
+
image::hdfs-external-cct-deployment1.png[]

== Virtualiza tus datos

=== Agente de Eureka

Para el uso de la BDL es necesario instalar el agente de Eureka. No es necesaria ninguna configuración adicional.

=== _Stratio Virtualizer_

_Stratio Virtualizer_ soporta la interacción con Apache Hadoop® (HDFS). Es posible configurar _Stratio Virtualizer_ de tres formas distintas:

* Apache Hadoop® (HDFS) interno.
+
Debes dejar toda la sección de Apache Hadoop® (HDFS) por defecto y seleccionar en la sección 'Service Discovery/HDFS user for connection' el Apache Hadoop® (HDFS) que se quiere configurar.
+
image::hdfs-virtualizer-deployment.png[]

* Apache Hadoop® (HDFS) externo.
+
Debes seguir cumplir con estos pasos:
+
* Tener un _ConfigMap_ que contenga el _hdfs-site.xml_ y el _core-site.xml_.
* Tener un _ConfigMap_ que contenga el _krb5.conf_ configurado.
* Crear los secretos en _Stratio KMS_. En este caso se usará el método de autenticación por Kerberos.
+
--
El secreto que debes subir consta de dos claves:

** _{ServiceID Virtualizer}.{Tenant}-{Namespace}_keytab_: corresponde al _keytab_ codificado en Base64.
** _{ServiceID Virtualizer}.{Tenant}-{Namespace}_principal_: corresponde al _principal_ con el que se va hacer _login_ en el Apache Hadoop® (HDFS) asociado al _keytab_.
--
+
NOTE: En este caso no es necesario seleccionar ningún Apache Hadoop® (HDFS) en la sección de _Service discovery_.

* Multi-HDFS.
+
_Stratio Virtualizer_ permite tener varios HDFS configurados. Para ello, debes ir a la sección 'Environment' de la configuración de _Stratio Virtualizer_ y, tras activar la opción general "Enable multiple HDFS", se desplegarán varias secciones similares, una por cada HDFS al que se quiere acceder. Podrás habilitar cada una de esas secciones completando estas tres opciones:
+
** _External hdfs name_: nombre identificativo del Apache Hadoop® (HDFS) externo. Debe seguir el formato `{nombre_HDFS}.{Namespace}`. Ejemplo: _hdfs2.stratio-datastores_.
** _External hdfs configuration URI_: ruta donde se encuentran los ficheros _core-site.xml_ y _hdfs-site.xml_.
** _External hdfs Keytab Vault path_: ruta de _Stratio KMS_ donde se encuentran los datos del _principal_ y el _keytab_ codificado en Base64. Si es un Apache Hadoop® (HDFS) interno, se puede usar el _keytab_ de _Stratio Virtualizer_ especificando en este campo dicha ruta. Ejemplo: _/v1/userland/kerberos/virtualizer.stratio-apps_.
+
image::hdfs-multi-virtualizer-deployment.png[]
+
NOTE: Para el _External hdfs configuration URI_ es necesario tener un servidor web o similar desde donde se descargarán los ficheros _core-site.xml_ y _hdfs.site.xml_.
+
[NOTE]
====
En caso de que el segundo Apache Hadoop® (HDFS) sea externo, el secreto que debes subir constará de dos claves:

* _keytab_: corresponde al _keytab_ codificado en Base64.
* _principal_ : corresponde al _principal_ con el que se va hacer _login_ en el Apache Hadoop® (HDFS) asociado al _keytab_.
====

== Transforma tus datos

=== _Stratio Rocket_

Para configurar un HDFS en _Stratio Rocket_, debes dejar toda la sección de Apache Hadoop® (HDFS) por defecto y seleccionar en la sección 'Service Discovery/HDFS user for connection' el Apache Hadoop® (HDFS) que se quiere configurar.

image::hdfs-rocket-cct-deployment.png[]

* Multi-HDFS
+
_Stratio Rocket_ permite tener varios HDFS configurados. Para ello, debes ir a la sección 'External Services' de la configuración de _Stratio Rocket_ y, tras activar la opción general "Enable multiple HDFS", se desplegarán varias secciones similares, una por cada HDFS al que se quiere acceder. Podrás habilitar cada una de esas secciones completando estas tres opciones:
+
** _External hdfs name_: nombre identificativo del Apache Hadoop® (HDFS) externo. Debe seguir el formato `{nombre_HDFS}.{Namespace}`. Ejemplo: _hdfs2.stratio-datastores_.
** _External hdfs configuration URI_: ruta donde se encuentran los ficheros _core-site.xml_ y _hdfs-site.xml_.
** _External hdfs Keytab Vault path_: ruta de _Stratio KMS_ donde se encuentran los datos del _principal_ y el _keytab_ codificado en Base64. Si es un Apache Hadoop® (HDFS) interno, se puede usar el _keytab_ de _Stratio Virtualizer_ especificando en este campo dicha ruta. Ejemplo: _/v1/userland/kerberos/virtualizer.stratio-apps_.
+
image::hdfs-multi-rocket-cct-deployment.png[]
+
[NOTE]
====
En caso de que el segundo Apache Hadoop® (HDFS) sea externo, el secreto que debes subir constará de dos claves:

* _keytab_: corresponde al _keytab_ codificado en Base64.
* _principal_: corresponde al _principal_ con el que se va hacer _login_ en el Apache Hadoop® (HDFS) asociado al _keytab_.
====

=== _Stratio Intelligence_

Para el uso de _Stratio Intelligence_ no es necesario aplicar ninguna configuración extra.
